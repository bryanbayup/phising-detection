{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMmFnSH9uLzf9FuZKisjDDA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanbayup/phising-detection/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    TFAutoModelForMaskedLM,\n",
        "    create_optimizer,\n",
        "    AutoTokenizer\n",
        ")\n",
        "from tensorflow.keras.utils import Sequence"
      ],
      "metadata": {
        "id": "YHdUtgCx5TXO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationDataset(Sequence):\n",
        "    def __init__(self,\n",
        "                 data_path,\n",
        "                 tokenizer,\n",
        "                 max_len=128,\n",
        "                 batch_size=16,\n",
        "                 mlm_probability=0.15,\n",
        "                 nsp_ratio=0.5):\n",
        "        self.data_path = data_path\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.batch_size = batch_size\n",
        "        self.mlm_probability = mlm_probability\n",
        "        self.nsp_ratio = nsp_ratio\n",
        "\n",
        "        with open(self.data_path, 'r', encoding='utf-8') as f:\n",
        "            self.data = json.load(f)\n",
        "\n",
        "        self.samples = self.create_samples(self.data)\n",
        "\n",
        "    def create_samples(self, data):\n",
        "        samples = []\n",
        "        for conv in data:\n",
        "            turns = conv['turns']\n",
        "            for i in range(len(turns)-1):\n",
        "                current_utt = turns[i]['utterance']\n",
        "                next_utt = turns[i+1]['utterance']\n",
        "\n",
        "                if np.random.rand() < self.nsp_ratio:\n",
        "                    is_next = 1\n",
        "                else:\n",
        "                    random_conv = np.random.choice(data)\n",
        "                    random_turn = np.random.choice(random_conv['turns'])\n",
        "                    next_utt = random_turn['utterance']\n",
        "                    is_next = 0\n",
        "\n",
        "                encoded = self.tokenizer.encode_plus(\n",
        "                    current_utt,\n",
        "                    next_utt,\n",
        "                    max_length=self.max_len,\n",
        "                    truncation=True,\n",
        "                    padding='max_length',\n",
        "                    return_tensors='np'\n",
        "                )\n",
        "\n",
        "                input_ids = encoded['input_ids'][0]\n",
        "                attention_mask = encoded['attention_mask'][0]\n",
        "                token_type_ids = encoded['token_type_ids'][0]\n",
        "\n",
        "                input_ids_masked, mlm_labels = self.mask_tokens(input_ids)\n",
        "                dialog_context = np.zeros((768,), dtype=np.float32)\n",
        "\n",
        "                samples.append({\n",
        "                    'input_ids': input_ids_masked,\n",
        "                    'attention_mask': attention_mask,\n",
        "                    'token_type_ids': token_type_ids,\n",
        "                    'mlm_labels': mlm_labels,\n",
        "                    'nsp_label': is_next,\n",
        "                    'dialog_context': dialog_context\n",
        "                })\n",
        "        return samples\n",
        "\n",
        "    def mask_tokens(self, input_ids):\n",
        "        input_ids = input_ids.copy()\n",
        "        mlm_labels = np.full_like(input_ids, -100)\n",
        "        special_ids = {101, 102, 0}\n",
        "        candidate_positions = [i for i, token_id in enumerate(input_ids) if token_id not in special_ids]\n",
        "\n",
        "        num_to_mask = max(1, int(len(candidate_positions)*self.mlm_probability))\n",
        "        mask_positions = np.random.choice(candidate_positions, num_to_mask, replace=False)\n",
        "\n",
        "        for pos in mask_positions:\n",
        "            mlm_labels[pos] = input_ids[pos]\n",
        "            rand = np.random.rand()\n",
        "            if rand < 0.8:\n",
        "                input_ids[pos] = 103\n",
        "            elif rand < 0.9:\n",
        "                input_ids[pos] = np.random.randint(999, 30000)\n",
        "            else:\n",
        "                pass\n",
        "        return input_ids, mlm_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.samples)/self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch = self.samples[idx*self.batch_size: (idx+1)*self.batch_size]\n",
        "        input_ids = np.array([s['input_ids'] for s in batch], dtype=np.int32)\n",
        "        attention_mask = np.array([s['attention_mask'] for s in batch], dtype=np.int32)\n",
        "        token_type_ids = np.array([s['token_type_ids'] for s in batch], dtype=np.int32)\n",
        "        mlm_labels = np.array([s['mlm_labels'] for s in batch], dtype=np.int32)\n",
        "        nsp_labels = np.array([s['nsp_label'] for s in batch], dtype=np.int32)\n",
        "        dialog_context = np.array([s['dialog_context'] for s in batch], dtype=np.float32)\n",
        "\n",
        "        return (input_ids, attention_mask, token_type_ids, dialog_context), {'labels': mlm_labels, 'next_sentence_label': nsp_labels}"
      ],
      "metadata": {
        "id": "9-_JjgEv5T2S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer & model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cahya/bert-base-indonesian-522M\")\n",
        "# Gunakan model TensorFlow\n",
        "base_model = TFAutoModelForMaskedLM.from_pretrained(\"cahya/bert-base-indonesian-522M\", from_pt=True)\n",
        "\n",
        "class CustomDialogModel(tf.keras.Model):\n",
        "    def __init__(self, base_model):\n",
        "        super(CustomDialogModel, self).__init__()\n",
        "        self.bert_pretrain = base_model\n",
        "        self.context_dense = tf.keras.layers.Dense(768, activation='relu')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        input_ids, attention_mask, token_type_ids, dialog_context = inputs\n",
        "        # TFAutoModelForMaskedLM memiliki model TF di dalamnya\n",
        "        outputs = self.bert_pretrain.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "        pooled_output = outputs.pooler_output\n",
        "\n",
        "        dialog_ctx_emb = self.context_dense(dialog_context)\n",
        "        combined_pooled = pooled_output + dialog_ctx_emb\n",
        "\n",
        "        prediction_scores, seq_relationship_score = self.bert_pretrain.cls(\n",
        "            sequence_output,\n",
        "            combined_pooled\n",
        "        )\n",
        "\n",
        "        return prediction_scores, seq_relationship_score\n",
        "\n",
        "class CustomTrainer(tf.keras.Model):\n",
        "    def __init__(self, dialog_model):\n",
        "        super(CustomTrainer, self).__init__()\n",
        "        self.dialog_model = dialog_model\n",
        "        self.loss_fct_mlm = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "        self.loss_fct_nsp = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        (input_ids, attention_mask, token_type_ids, dialog_context) = inputs\n",
        "        prediction_scores, seq_relationship_score = self.dialog_model(\n",
        "            (input_ids, attention_mask, token_type_ids, dialog_context),\n",
        "            training=training\n",
        "        )\n",
        "        return prediction_scores, seq_relationship_score\n",
        "\n",
        "    def train_step(self, data):\n",
        "        (input_ids, attention_mask, token_type_ids, dialog_context), labels = data\n",
        "        mlm_labels = labels['labels']\n",
        "        nsp_labels = labels['next_sentence_label']\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            prediction_scores, seq_relationship_score = self(\n",
        "                (input_ids, attention_mask, token_type_ids, dialog_context),\n",
        "                training=True\n",
        "            )\n",
        "\n",
        "            mlm_active_loss = tf.not_equal(mlm_labels, -100)\n",
        "            mlm_loss = self.loss_fct_mlm(mlm_labels, prediction_scores)\n",
        "            mlm_loss = (tf.reduce_sum(mlm_loss * tf.cast(mlm_active_loss, dtype=mlm_loss.dtype)) /\n",
        "                         (tf.reduce_sum(tf.cast(mlm_active_loss, tf.float32)) + 1e-5))\n",
        "\n",
        "            nsp_loss = self.loss_fct_nsp(nsp_labels, seq_relationship_score)\n",
        "            nsp_loss = tf.reduce_mean(nsp_loss)\n",
        "\n",
        "            total_loss = mlm_loss + nsp_loss\n",
        "\n",
        "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(total_loss)\n",
        "        return {\"loss\": total_loss, \"mlm_loss\": mlm_loss, \"nsp_loss\": nsp_loss}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        (input_ids, attention_mask, token_type_ids, dialog_context), labels = data\n",
        "        mlm_labels = labels['labels']\n",
        "        nsp_labels = labels['next_sentence_label']\n",
        "\n",
        "        prediction_scores, seq_relationship_score = self(\n",
        "            (input_ids, attention_mask, token_type_ids, dialog_context),\n",
        "            training=False\n",
        "        )\n",
        "\n",
        "        mlm_active_loss = tf.not_equal(mlm_labels, -100)\n",
        "        mlm_loss = self.loss_fct_mlm(mlm_labels, prediction_scores)\n",
        "        mlm_loss = (tf.reduce_sum(mlm_loss * tf.cast(mlm_active_loss, dtype=mlm_loss.dtype)) /\n",
        "                     (tf.reduce_sum(tf.cast(mlm_active_loss, tf.float32)) + 1e-5))\n",
        "\n",
        "        nsp_loss = self.loss_fct_nsp(nsp_labels, seq_relationship_score)\n",
        "        nsp_loss = tf.reduce_mean(nsp_loss)\n",
        "\n",
        "        total_loss = mlm_loss + nsp_loss\n",
        "        return {\"loss\": total_loss, \"mlm_loss\": mlm_loss, \"nsp_loss\": nsp_loss}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksNJfi3s5dvu",
        "outputId": "e95cfd83-00ef-44ce-b2d4-91ef014697be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['bert.embeddings.position_ids', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"data2.json\"\n",
        "train_dataset = ConversationDataset(data_path=data_path, tokenizer=tokenizer, max_len=128, batch_size=8)\n",
        "val_dataset = ConversationDataset(data_path=data_path, tokenizer=tokenizer, max_len=128, batch_size=8)\n",
        "\n",
        "num_epochs = 2\n",
        "initial_lr = 3e-5\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n",
        "\n",
        "dialog_model = CustomDialogModel(base_model)\n",
        "trainer_model = CustomTrainer(dialog_model)\n",
        "trainer_model.compile(optimizer=optimizer)\n",
        "\n",
        "history = trainer_model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=num_epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "SySZRkB-5jHB",
        "outputId": "1c4d050c-c787-4418-9fca-6cca096b9047"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:1383: UserWarning: Layer 'custom_dialog_model_3' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''None values not supported.''\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:1383: UserWarning: Layer 'custom_trainer_3' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''Exception encountered when calling CustomDialogModel.call().\n",
            "\n",
            "\u001b[1mNone values not supported.\u001b[0m\n",
            "\n",
            "Arguments received by CustomDialogModel.call():\n",
            "  • inputs=('tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 768), dtype=float32)')\n",
            "  • training=True''\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling CustomDialogModel.call().\n\n\u001b[1mNone values not supported.\u001b[0m\n\nArguments received by CustomDialogModel.call():\n  • inputs=('tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 768), dtype=float32)')\n  • training=True",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0cb09c548439>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrainer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m history = trainer_model.fit(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-f66d08ba071a>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             prediction_scores, seq_relationship_score = self(\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialog_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-f66d08ba071a>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialog_context\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         prediction_scores, seq_relationship_score = self.dialog_model(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialog_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-f66d08ba071a>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdialog_ctx_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdialog_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcombined_pooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdialog_ctx_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         prediction_scores, seq_relationship_score = self.bert_pretrain.cls(\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling CustomDialogModel.call().\n\n\u001b[1mNone values not supported.\u001b[0m\n\nArguments received by CustomDialogModel.call():\n  • inputs=('tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 768), dtype=float32)')\n  • training=True"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M1QgTgHi6C6M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}