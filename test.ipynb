{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMreIgVlOmbgxscOFAnrE5S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "56ed564123124e01a265be2b4c8a42cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "User Input:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_2afbf16c0b3f436c98532aed4edec9c5",
            "placeholder": "Ketik pertanyaan Anda di sini...",
            "style": "IPY_MODEL_f09234e937ae49499349796086d786a2",
            "value": ""
          }
        },
        "2afbf16c0b3f436c98532aed4edec9c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f09234e937ae49499349796086d786a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cb8f5a5a8ca484c90cd58ab324b8b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Kirim",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_300297bf4a864ee985b7d953b62b7553",
            "style": "IPY_MODEL_e7e15f2b97db47e781a00e1ccae2095f",
            "tooltip": ""
          }
        },
        "300297bf4a864ee985b7d953b62b7553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e15f2b97db47e781a00e1ccae2095f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0be1f579ee24469ab89c712855ceeba9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_68dee8ba5f3a449899c3ad1629e53a1a",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "User: Anjing saya tampak lelah dan perutnya terlihat membesar\n",
                  "Chatbot: Gejala ini dapat mengindikasikan Penyakit Cushing atau kondisi kesehatan lain. Apakah anjing Anda menunjukkan tanda-tanda lain seperti kerontokan bulu?\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "User: Tidak ada tanda-tanda kerontokan bulu, hanya perutnya saja yang membesar.\n",
                  "Chatbot: Segera bawa anjing Anda ke dokter hewan untuk pemeriksaan menyeluruh dan pengobatan lebih lanjut.\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "User: Saya menemukan seekor kucing dengan luka di kaki di taman\n",
                  "Chatbot: Terima kasih atas laporannya. Apakah Anda ingin melaporkan kucing ini melalui fitur emergency?\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "User: Ada anjing dengan kulit merah dan gatal di depan sekolah.\n",
                  "Chatbot: Anjing tersebut mungkin mengalami masalah kulit seperti kudis. Laporkan melalui fitur emergency untuk mendapatkan bantuan.\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "User: Anjing tersebut mungkin mengalami masalah kulit seperti kudis. Laporkan melalui fitur emergency untuk mendapatkan bantuan\n",
                  "Chatbot: Anjing tersebut mungkin mengalami masalah kulit seperti kudis. Laporkan melalui fitur emergency untuk mendapatkan bantuan.\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "User: Ada kucing muntah dan diare berdarah di pasar.\n",
                  "Chatbot: Gejala ini menunjukkan kemungkinan Feline Panleukopenia. Segera gunakan fitur emergency untuk mendapatkan bantuan.\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "User: Saya melihat seekor kucing sakit di depan toko.\n",
                  "Chatbot: Terima kasih atas laporannya. Apakah kucing tersebut menunjukkan gejala seperti demam atau muntah?\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "User: Kucing terlihat demam dan bersin-bersin.\n",
                  "Chatbot: Kucing tersebut mungkin terkena Feline Calicivirus. Sebaiknya segera hubungi komunitas terdekat melalui fitur emergency.\n",
                  "\n"
                ]
              }
            ]
          }
        },
        "68dee8ba5f3a449899c3ad1629e53a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanbayup/phising-detection/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim keras-tuner imbalanced-learn Sastrawi sentencepiece seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu_36DqYCW2O",
        "outputId": "03d4c77b-48c1-46f6-c4b5-8fb88fad414c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m857.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=71c706ad119ac9c2c97266e4a15c8b43d058a8d67e97789fd6e698b5c4847ebc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: Sastrawi, kt-legacy, seqeval, keras-tuner\n",
            "Successfully installed Sastrawi-1.0.1 keras-tuner-1.4.7 kt-legacy-1.0.5 seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download FastText\n",
        "!wget -O id.tar.gz \"https://www.dropbox.com/scl/fi/sju4o3keikox69euw51vy/id.tar.gz?rlkey=5jr3ijtbdwfahq7xcgig28qvy&e=1&st=gntzkzeo&dl=1\"\n",
        "!tar -xzf id.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfaW2FTgMC1V",
        "outputId": "9c11e301-4ffb-49c6-ab6f-3b6d5e602093"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-06 09:01:01--  https://www.dropbox.com/scl/fi/sju4o3keikox69euw51vy/id.tar.gz?rlkey=5jr3ijtbdwfahq7xcgig28qvy&e=1&st=gntzkzeo&dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc7e43568fd796229ffc0a4f29d9.dl.dropboxusercontent.com/cd/0/inline/CfsSAnFxfMRmJDQPTYBhu9zlAAV5b5WrkiGbXaVzK7Q7-89aWp4hlxEdvWwjgpIMQQg_3Mf_AM8AlD-UPuwjyCPeI9D5Ky0WvwALlimffXB9Hrn9U1ozZCebcNxM4zqedX0/file?dl=1# [following]\n",
            "--2024-12-06 09:01:02--  https://uc7e43568fd796229ffc0a4f29d9.dl.dropboxusercontent.com/cd/0/inline/CfsSAnFxfMRmJDQPTYBhu9zlAAV5b5WrkiGbXaVzK7Q7-89aWp4hlxEdvWwjgpIMQQg_3Mf_AM8AlD-UPuwjyCPeI9D5Ky0WvwALlimffXB9Hrn9U1ozZCebcNxM4zqedX0/file?dl=1\n",
            "Resolving uc7e43568fd796229ffc0a4f29d9.dl.dropboxusercontent.com (uc7e43568fd796229ffc0a4f29d9.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uc7e43568fd796229ffc0a4f29d9.dl.dropboxusercontent.com (uc7e43568fd796229ffc0a4f29d9.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CfukARsin3hfFsF5mfbN8VvgDf2mAOhADY6XDpNnbmOozbyAKpqpxjR2c8DdhBK4M-gv2a1K8HZq5nIz1_MNGvm-75X3KGsw3z5Vw6n4_huW0GeDMCTXk1WjJuew3MjAnommS-oMaIpdv3OSFzAzz06uP4lqQaULWDJ9Ls0zCJEOJtiFCRiHUZ0BwTHGcgH1V4lhNjtLo0DEC6gRDvOHlCgagV654VZSAa9tGBf9codpDb8raljA2jgvPPcBCKGuAWlCg6pkQz6S3Hk5004tHUkBJ2lyA-jXzjNUbLDr55Gx4SmHbnCQbkG12qKrqlc4VRYk03ljEZBYCZoZa7FZStIu3j-3ErWjIPRJMnLzVgLcdw/file?dl=1 [following]\n",
            "--2024-12-06 09:01:02--  https://uc7e43568fd796229ffc0a4f29d9.dl.dropboxusercontent.com/cd/0/inline2/CfukARsin3hfFsF5mfbN8VvgDf2mAOhADY6XDpNnbmOozbyAKpqpxjR2c8DdhBK4M-gv2a1K8HZq5nIz1_MNGvm-75X3KGsw3z5Vw6n4_huW0GeDMCTXk1WjJuew3MjAnommS-oMaIpdv3OSFzAzz06uP4lqQaULWDJ9Ls0zCJEOJtiFCRiHUZ0BwTHGcgH1V4lhNjtLo0DEC6gRDvOHlCgagV654VZSAa9tGBf9codpDb8raljA2jgvPPcBCKGuAWlCg6pkQz6S3Hk5004tHUkBJ2lyA-jXzjNUbLDr55Gx4SmHbnCQbkG12qKrqlc4VRYk03ljEZBYCZoZa7FZStIu3j-3ErWjIPRJMnLzVgLcdw/file?dl=1\n",
            "Reusing existing connection to uc7e43568fd796229ffc0a4f29d9.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2333351997 (2.2G) [application/binary]\n",
            "Saving to: ‘id.tar.gz’\n",
            "\n",
            "id.tar.gz           100%[===================>]   2.17G  33.3MB/s    in 62s     \n",
            "\n",
            "2024-12-06 09:02:05 (35.8 MB/s) - ‘id.tar.gz’ saved [2333351997/2333351997]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import (Dense, Input, Dropout, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D,\n",
        "                                     TimeDistributed, Embedding, GlobalAveragePooling1D, Layer, Lambda)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "import nltk\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from keras_tuner import HyperModel, RandomSearch\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from nltk.corpus import stopwords\n",
        "from seqeval.metrics import classification_report as seq_classification_report\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# --------------------------------------\n",
        "# Load FastText\n",
        "# --------------------------------------\n",
        "try:\n",
        "    fasttext_model = KeyedVectors.load_word2vec_format('id.vec', binary=False)\n",
        "    print(\"FastText 'id.vec' berhasil dimuat.\")\n",
        "except Exception as e:\n",
        "    print(f\"Gagal memuat 'id.vec': {e}\")\n",
        "    raise ValueError(\"Gagal memuat FastText.\")\n",
        "\n",
        "# --------------------------------------\n",
        "# Load Data\n",
        "# Pastikan 'data2.json' adalah file yang berisi dataset terakhir yang Anda berikan.\n",
        "# --------------------------------------\n",
        "with open('data2.json', 'r', encoding='utf-8') as f:\n",
        "    conversations = json.load(f)\n",
        "\n",
        "# --------------------------------------\n",
        "# Ekstrak Data\n",
        "# --------------------------------------\n",
        "def char_offset_to_token_labels(utterance, entities, tokenizer=lambda x: x.split()):\n",
        "    tokens = tokenizer(utterance)\n",
        "    labels = [\"O\"] * len(tokens)\n",
        "    char_pos = 0\n",
        "    token_ranges = []\n",
        "    for t in tokens:\n",
        "        start_pos = char_pos\n",
        "        end_pos = start_pos + len(t)\n",
        "        token_ranges.append((start_pos, end_pos))\n",
        "        char_pos = end_pos + 1\n",
        "    for ent in entities:\n",
        "        ent_start = ent['start']\n",
        "        ent_end = ent['end']\n",
        "        ent_type = ent['entity'].upper()\n",
        "        ent_token_positions = []\n",
        "        for i, (ts, te) in enumerate(token_ranges):\n",
        "            if not (te <= ent_start or ts >= ent_end):\n",
        "                ent_token_positions.append(i)\n",
        "        if len(ent_token_positions) > 0:\n",
        "            labels[ent_token_positions[0]] = \"B-\" + ent_type\n",
        "            for p in ent_token_positions[1:]:\n",
        "                labels[p] = \"I-\" + ent_type\n",
        "    return tokens, labels\n",
        "\n",
        "user_utterances = []\n",
        "intents = []\n",
        "entity_labels = []\n",
        "\n",
        "for conv in conversations:\n",
        "    for turn in conv[\"turns\"]:\n",
        "        if turn[\"speaker\"] == \"user\":\n",
        "            utt = turn[\"utterance\"]\n",
        "            ents = turn.get(\"entities\", [])\n",
        "            intent = turn.get(\"intent\", \"None\")\n",
        "            tokens, ner_tags = char_offset_to_token_labels(utt, ents)\n",
        "            user_utterances.append(tokens)\n",
        "            intents.append(intent)\n",
        "            entity_labels.append(ner_tags)\n",
        "\n",
        "# --------------------------------------\n",
        "# Preprocessing Text\n",
        "# --------------------------------------\n",
        "with open('stopword_list_tala.txt', 'r', encoding='utf-8') as f:\n",
        "    stop_words = f.read().splitlines()\n",
        "stop_words = set(word.strip().lower() for word in stop_words)\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = clean_text(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "utterances_joined = [' '.join(utt) for utt in user_utterances]\n",
        "utterances_clean = [preprocess_text(u) for u in utterances_joined]\n",
        "\n",
        "df_data = pd.DataFrame({\n",
        "    'utterances': utterances_joined,\n",
        "    'intent': intents,\n",
        "    'entities': entity_labels,\n",
        "    'utterances_clean': utterances_clean\n",
        "})\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_data['intent_label'] = label_encoder.fit_transform(df_data['intent'])\n",
        "\n",
        "# Balance data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X = df_data.index.values.reshape(-1, 1)\n",
        "y = df_data['intent_label']\n",
        "X_ros, y_ros = ros.fit_resample(X, y)\n",
        "df_balanced = df_data.loc[X_ros.flatten()].reset_index(drop=True)\n",
        "df_balanced['intent_label'] = y_ros\n",
        "df_balanced['intent'] = label_encoder.inverse_transform(df_balanced['intent_label'])\n",
        "\n",
        "# --------------------------------------\n",
        "# Split Data for Intent Classification\n",
        "# --------------------------------------\n",
        "texts = df_balanced['utterances_clean'].tolist()\n",
        "labels = df_balanced['intent_label'].tolist()\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='')\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "val_sequences = tokenizer.texts_to_sequences(val_texts)\n",
        "max_seq_length = max(max(len(seq) for seq in train_sequences), max(len(seq) for seq in val_sequences))\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_seq_length, padding='post')\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels_cat = to_categorical(train_labels, num_classes=num_classes)\n",
        "val_labels_cat = to_categorical(val_labels, num_classes=num_classes)\n",
        "\n",
        "embedding_dim = 300  # Gunakan embedding dim yang sama seperti fasttext\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, idx in word_index.items():\n",
        "    if word in fasttext_model:\n",
        "        embedding_matrix[idx] = fasttext_model[word]\n",
        "    else:\n",
        "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
        "\n",
        "# --------------------------------------\n",
        "# NER Data\n",
        "# --------------------------------------\n",
        "all_labels = set()\n",
        "for tags in df_balanced['entities']:\n",
        "    for t in tags:\n",
        "        if t != 'O':\n",
        "            all_labels.add(t)\n",
        "all_labels.add('O')\n",
        "all_labels = sorted(list(all_labels))\n",
        "ner_label_encoder = {label: idx for idx, label in enumerate(all_labels)}\n",
        "ner_label_decoder = {idx: label for label, idx in ner_label_encoder.items()}\n",
        "\n",
        "def encode_tags(tags, max_len):\n",
        "    tag_ids = [ner_label_encoder[t] for t in tags]\n",
        "    tag_ids = tag_ids[:max_len] + [ner_label_encoder['O']]*(max_len - len(tag_ids))\n",
        "    return tag_ids\n",
        "\n",
        "def text_to_sequence(text):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    return seq[0]\n",
        "\n",
        "X_ner = []\n",
        "Y_ner = []\n",
        "for i, row in df_balanced.iterrows():\n",
        "    seq = text_to_sequence(row['utterances_clean'])\n",
        "    seq_padded = seq[:max_seq_length] + [0]*(max_seq_length - len(seq))\n",
        "    X_ner.append(seq_padded)\n",
        "    tag_ids = encode_tags(row['entities'], max_seq_length)\n",
        "    Y_ner.append(tag_ids)\n",
        "\n",
        "X_ner = np.array(X_ner)\n",
        "Y_ner = np.array(Y_ner)\n",
        "Y_ner = to_categorical(Y_ner, num_classes=len(ner_label_encoder))\n",
        "\n",
        "train_texts_ner, val_texts_ner, train_labels_ner, val_labels_ner = train_test_split(\n",
        "    X_ner,\n",
        "    Y_ner,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --------------------------------------\n",
        "# Attention Layer\n",
        "# --------------------------------------\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='att_weight', shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='att_bias', shape=(1,),\n",
        "                                 initializer='zeros', trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = tf.squeeze(tf.tensordot(x, self.W, axes=1), axis=-1) + self.b\n",
        "        alpha = tf.nn.softmax(e)\n",
        "        alpha = tf.expand_dims(alpha, axis=-1)\n",
        "        context = x * alpha\n",
        "        return tf.reduce_sum(context, axis=1)  # shape: (batch, features)\n",
        "\n",
        "# --------------------------------------\n",
        "# Model Intent dengan BiLSTM + Attention\n",
        "# --------------------------------------\n",
        "def build_intent_model(embedding_matrix, max_seq_length, num_classes, l2_reg=1e-3):\n",
        "    inputs = Input(shape=(max_seq_length,), dtype='int32')\n",
        "    emb = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                    output_dim=embedding_matrix.shape[1],\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_seq_length,\n",
        "                    trainable=True, mask_zero=True)(inputs)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(emb)\n",
        "    att = AttentionLayer()(x)\n",
        "    dense = Dense(128, activation='relu', kernel_regularizer=l2(l2_reg))(att)\n",
        "    dropout = Dropout(0.5)(dense)\n",
        "    outputs = Dense(num_classes, activation='softmax')(dropout)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_intent = build_intent_model(embedding_matrix, max_seq_length, num_classes)\n",
        "early_intent = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model_intent.fit(\n",
        "    train_padded, train_labels_cat,\n",
        "    validation_data=(val_padded, val_labels_cat),\n",
        "    epochs=30, batch_size=16,\n",
        "    callbacks=[early_intent]\n",
        ")\n",
        "\n",
        "# --------------------------------------\n",
        "# Model NER dengan BiLSTM + Attention\n",
        "# --------------------------------------\n",
        "def build_ner_model(embedding_matrix, max_seq_length, num_entities, l2_reg=1e-3):\n",
        "    inputs = Input(shape=(max_seq_length,))\n",
        "    emb = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                    output_dim=embedding_matrix.shape[1],\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=True)(inputs) # mask_zero dihapus\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(emb)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(x)\n",
        "\n",
        "    # Tetap gunakan TimeDistributed Dense untuk output NER\n",
        "    td = TimeDistributed(Dense(num_entities, activation='softmax'))(x)\n",
        "    model = Model(inputs, td)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_ner = build_ner_model(embedding_matrix, max_seq_length, len(ner_label_encoder))\n",
        "early_ner = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model_ner.fit(\n",
        "    train_texts_ner, train_labels_ner,\n",
        "    validation_data=(val_texts_ner, val_labels_ner),\n",
        "    epochs=30, batch_size=16,\n",
        "    callbacks=[early_ner]\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss_intent, acc_intent = model_intent.evaluate(val_padded, val_labels_cat)\n",
        "print(\"Akurasi Intent:\", acc_intent)\n",
        "\n",
        "loss_ner, acc_ner = model_ner.evaluate(val_texts_ner, val_labels_ner)\n",
        "print(\"Akurasi NER:\", acc_ner)\n",
        "\n",
        "# --------------------------------------\n",
        "# Simpan Model\n",
        "# --------------------------------------\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('encoders', exist_ok=True)\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "model_intent.save('models/model_intent.keras')\n",
        "model_ner.save('models/model_ner.keras')\n",
        "\n",
        "with open('encoders/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('encoders/label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('encoders/ner_label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(ner_label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "df_utterances = df_balanced[['utterances', 'intent', 'utterances_clean']].reset_index(drop=True)\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(df_utterances['utterances_clean'])\n",
        "with open('data/vectorizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "intent_animal_mapping = {\n",
        "    \"Melaporkan Hewan Terlantar\": [\"kucing\", \"anjing\"],\n",
        "    \"Mendiagnosis Gejala\": [\"kucing\", \"anjing\"],\n",
        "    \"Rekomendasi Penanganan Awal\": [\"kucing\", \"anjing\"],\n",
        "    \"Konfirmasi Laporan\": [\"kucing\", \"anjing\"],\n",
        "    \"Tindak Lanjut Laporan\": [\"kucing\", \"anjing\"],\n",
        "    \"Rekomendasi Tindakan\": [\"kucing\", \"anjing\"]\n",
        "}\n",
        "\n",
        "def predict_intent(text):\n",
        "    text_clean = preprocess_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_intent.predict(padded)\n",
        "    predicted_label = np.argmax(pred, axis=1)[0]\n",
        "    return label_encoder.inverse_transform([predicted_label])[0]\n",
        "\n",
        "def predict_entities(text):\n",
        "    text_clean = preprocess_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_ner.predict(padded)\n",
        "    pred_labels = np.argmax(pred[0], axis=-1)\n",
        "    tokens = tokenizer.sequences_to_texts(seq)[0].split()\n",
        "    entities = []\n",
        "    for idx, label_id in enumerate(pred_labels[:len(tokens)]):\n",
        "        label = ner_label_decoder[label_id]\n",
        "        if label != 'O':\n",
        "            entities.append({'entity': label.split('-')[1].lower(), 'value': tokens[idx]})\n",
        "    return entities\n",
        "\n",
        "def adjust_intent(intent, entities):\n",
        "    predicted_animals = intent_animal_mapping.get(intent, None)\n",
        "    entity_animals = [ent['value'].lower() for ent in entities if ent['entity'] == 'animal']\n",
        "    if entity_animals and predicted_animals:\n",
        "        user_animal = entity_animals[0]\n",
        "        if user_animal not in predicted_animals:\n",
        "            for i_name, animals in intent_animal_mapping.items():\n",
        "                if user_animal in animals:\n",
        "                    intent = i_name\n",
        "                    break\n",
        "            else:\n",
        "                intent = None\n",
        "    return intent\n",
        "\n",
        "def get_default_response():\n",
        "    default_responses = [\n",
        "        \"Maaf, saya belum bisa menjawab pertanyaan Anda.\",\n",
        "        \"Mohon diperjelas, saya belum mengerti konteksnya.\",\n",
        "        \"Silakan berikan informasi lebih detail.\",\n",
        "        \"Maaf, saya hanya diprogram untuk menjawab mengenai kucing dan anjing.\",\n",
        "        \"Saya sarankan konsultasi langsung ke dokter hewan.\"\n",
        "    ]\n",
        "    return random.choice(default_responses)\n",
        "\n",
        "def get_response(user_input, intent=None, entities=None):\n",
        "    # Untuk kesederhanaan, kita berikan respon tergantung intent:\n",
        "    # Jika tidak puas dengan ini, Anda bisa membuat mapping intent ke response yang lebih baik.\n",
        "    if intent == \"Mendiagnosis Gejala\":\n",
        "        return \"Berdasarkan gejalanya, kemungkinan ada masalah kesehatan. Saya sarankan segera periksakan ke dokter hewan.\"\n",
        "    elif intent == \"Rekomendasi Penanganan Awal\":\n",
        "        return \"Cobalah langkah penanganan awal seperti menjaga kebersihan, memberikan makanan ringan, dan konsultasikan ke dokter hewan jika berlanjut.\"\n",
        "    else:\n",
        "        return get_default_response()\n",
        "\n",
        "dialog_history = []\n",
        "MAX_HISTORY = 2\n",
        "\n",
        "def predict_intent_multi_turn(dialog_history, current_input):\n",
        "    history_context = dialog_history[-MAX_HISTORY:] if len(dialog_history) > MAX_HISTORY else dialog_history\n",
        "    combined_input = \" \".join(history_context + [current_input])\n",
        "    return predict_intent(combined_input)\n",
        "\n",
        "def predict_entities_multi_turn(dialog_history, current_input):\n",
        "    history_context = dialog_history[-MAX_HISTORY:] if len(dialog_history) > MAX_HISTORY else dialog_history\n",
        "    combined_input = \" \".join(history_context + [current_input])\n",
        "    return predict_entities(combined_input)\n",
        "\n",
        "def chatbot_response_multi_turn(user_input):\n",
        "    dialog_history.append(user_input)\n",
        "    intent = predict_intent_multi_turn(dialog_history, user_input)\n",
        "    entities = predict_entities_multi_turn(dialog_history, user_input)\n",
        "    adjusted = adjust_intent(intent, entities)\n",
        "    if adjusted is None:\n",
        "        response = get_default_response()\n",
        "    else:\n",
        "        response = get_response(user_input, adjusted, entities)\n",
        "        if not response:\n",
        "            response = get_default_response()\n",
        "    return response\n",
        "\n",
        "# --------------------------------------\n",
        "# TESTING DENGAN PERTANYAAN YANG DIMINTA\n",
        "# Gunakan data \"conv_043\", \"conv_044\", \"conv_045\" yang telah Anda berikan.\n",
        "# --------------------------------------\n",
        "\n",
        "print(\"=== Test Model dengan Pertanyaan dari conv_043 ===\")\n",
        "dialog_history.clear()\n",
        "test_turns_043 = [\n",
        "    \"Kucing saya sering batuk dan hidungnya berair. Apa yang salah?\",\n",
        "    \"Ya, rumah saya cukup dingin dan banyak debu akhir-akhir ini.\"\n",
        "]\n",
        "\n",
        "for t in test_turns_043:\n",
        "    print(\"User:\", t)\n",
        "    resp = chatbot_response_multi_turn(t)\n",
        "    print(\"Chatbot:\", resp, \"\\n\")\n",
        "\n",
        "print(\"=== Test Model dengan Pertanyaan dari conv_044 ===\")\n",
        "dialog_history.clear()\n",
        "test_turns_044 = [\n",
        "    \"Anjing saya tidak nafsu makan dan sering diare. Apa yang terjadi?\",\n",
        "    \"Tidak, hanya diare saja.\"\n",
        "]\n",
        "\n",
        "for t in test_turns_044:\n",
        "    print(\"User:\", t)\n",
        "    resp = chatbot_response_multi_turn(t)\n",
        "    print(\"Chatbot:\", resp, \"\\n\")\n",
        "\n",
        "print(\"=== Test Model dengan Pertanyaan dari conv_045 ===\")\n",
        "dialog_history.clear()\n",
        "test_turns_045 = [\n",
        "    \"Kucing saya sering mengeluarkan air mata dan matanya terlihat merah.\",\n",
        "    \"Ya, ada renovasi rumah dengan banyak debu.\"\n",
        "]\n",
        "\n",
        "for t in test_turns_045:\n",
        "    print(\"User:\", t)\n",
        "    resp = chatbot_response_multi_turn(t)\n",
        "    print(\"Chatbot:\", resp, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTZbrFVvM3UZ",
        "outputId": "a728549f-7967-4e60-a3d3-4322e8b5a3a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 'id.vec' berhasil dimuat.\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'attention_layer_3' (of type AttentionLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.4283 - loss: 1.6786 - val_accuracy: 0.5857 - val_loss: 1.2073\n",
            "Epoch 2/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5659 - loss: 1.1185 - val_accuracy: 0.7857 - val_loss: 0.8296\n",
            "Epoch 3/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.8532 - loss: 0.6916 - val_accuracy: 0.8857 - val_loss: 0.5088\n",
            "Epoch 4/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9165 - loss: 0.4109 - val_accuracy: 0.9000 - val_loss: 0.4215\n",
            "Epoch 5/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9462 - loss: 0.3122 - val_accuracy: 0.9143 - val_loss: 0.3324\n",
            "Epoch 6/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9808 - loss: 0.2270 - val_accuracy: 0.9143 - val_loss: 0.3351\n",
            "Epoch 7/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9775 - loss: 0.2177 - val_accuracy: 0.9143 - val_loss: 0.3826\n",
            "Epoch 8/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9917 - loss: 0.1755 - val_accuracy: 0.9143 - val_loss: 0.2648\n",
            "Epoch 9/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9905 - loss: 0.1532 - val_accuracy: 0.9429 - val_loss: 0.2809\n",
            "Epoch 10/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9888 - loss: 0.1692 - val_accuracy: 0.9429 - val_loss: 0.2237\n",
            "Epoch 11/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.1293 - val_accuracy: 0.9429 - val_loss: 0.2158\n",
            "Epoch 12/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9958 - loss: 0.1215 - val_accuracy: 0.9571 - val_loss: 0.2298\n",
            "Epoch 13/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.1116 - val_accuracy: 0.9714 - val_loss: 0.2084\n",
            "Epoch 14/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9943 - loss: 0.1176 - val_accuracy: 0.9571 - val_loss: 0.2531\n",
            "Epoch 15/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9920 - loss: 0.1164 - val_accuracy: 0.9571 - val_loss: 0.2003\n",
            "Epoch 16/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9977 - loss: 0.0982 - val_accuracy: 0.9714 - val_loss: 0.1585\n",
            "Epoch 17/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0918 - val_accuracy: 0.9714 - val_loss: 0.1701\n",
            "Epoch 18/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9968 - loss: 0.0946 - val_accuracy: 0.9714 - val_loss: 0.1677\n",
            "Epoch 19/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0828 - val_accuracy: 0.9714 - val_loss: 0.1751\n",
            "Epoch 20/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0779 - val_accuracy: 0.9714 - val_loss: 0.1891\n",
            "Epoch 21/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0748 - val_accuracy: 0.9714 - val_loss: 0.1675\n",
            "Epoch 1/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.6222 - loss: 1.7819 - val_accuracy: 0.7444 - val_loss: 0.9359\n",
            "Epoch 2/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.7399 - loss: 0.8697 - val_accuracy: 0.7540 - val_loss: 0.6838\n",
            "Epoch 3/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.7590 - loss: 0.6419 - val_accuracy: 0.7841 - val_loss: 0.6087\n",
            "Epoch 4/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7878 - loss: 0.5434 - val_accuracy: 0.8016 - val_loss: 0.5480\n",
            "Epoch 5/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.8254 - loss: 0.4626 - val_accuracy: 0.8159 - val_loss: 0.5485\n",
            "Epoch 6/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8185 - loss: 0.4580 - val_accuracy: 0.8286 - val_loss: 0.5088\n",
            "Epoch 7/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.8310 - loss: 0.4347 - val_accuracy: 0.8317 - val_loss: 0.4934\n",
            "Epoch 8/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.8476 - loss: 0.3991 - val_accuracy: 0.8270 - val_loss: 0.4951\n",
            "Epoch 9/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8680 - loss: 0.3528 - val_accuracy: 0.8476 - val_loss: 0.4701\n",
            "Epoch 10/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8733 - loss: 0.3336 - val_accuracy: 0.8476 - val_loss: 0.4771\n",
            "Epoch 11/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.8807 - loss: 0.3075 - val_accuracy: 0.8540 - val_loss: 0.4597\n",
            "Epoch 12/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9006 - loss: 0.2741 - val_accuracy: 0.8651 - val_loss: 0.4521\n",
            "Epoch 13/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8870 - loss: 0.2979 - val_accuracy: 0.8714 - val_loss: 0.4361\n",
            "Epoch 14/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.8998 - loss: 0.2712 - val_accuracy: 0.8667 - val_loss: 0.4455\n",
            "Epoch 15/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9147 - loss: 0.2397 - val_accuracy: 0.8698 - val_loss: 0.4702\n",
            "Epoch 16/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9068 - loss: 0.2395 - val_accuracy: 0.8810 - val_loss: 0.4280\n",
            "Epoch 17/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9242 - loss: 0.2121 - val_accuracy: 0.8810 - val_loss: 0.4409\n",
            "Epoch 18/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.9219 - loss: 0.2155 - val_accuracy: 0.8794 - val_loss: 0.4444\n",
            "Epoch 19/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.9462 - loss: 0.1622 - val_accuracy: 0.8873 - val_loss: 0.4571\n",
            "Epoch 20/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9352 - loss: 0.1788 - val_accuracy: 0.8905 - val_loss: 0.4364\n",
            "Epoch 21/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9382 - loss: 0.1775 - val_accuracy: 0.8937 - val_loss: 0.4413\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9701 - loss: 0.1637\n",
            "Akurasi Intent: 0.9714285731315613\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8741 - loss: 0.4604\n",
            "Akurasi NER: 0.8809524774551392\n",
            "=== Test Model dengan Pertanyaan dari conv_043 ===\n",
            "User: Kucing saya sering batuk dan hidungnya berair. Apa yang salah?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'attention_layer_3' (of type AttentionLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x791c8ecb0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767ms/step\n",
            "Chatbot: Berdasarkan gejalanya, kemungkinan ada masalah kesehatan. Saya sarankan segera periksakan ke dokter hewan. \n",
            "\n",
            "User: Ya, rumah saya cukup dingin dan banyak debu akhir-akhir ini.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Chatbot: Cobalah langkah penanganan awal seperti menjaga kebersihan, memberikan makanan ringan, dan konsultasikan ke dokter hewan jika berlanjut. \n",
            "\n",
            "=== Test Model dengan Pertanyaan dari conv_044 ===\n",
            "User: Anjing saya tidak nafsu makan dan sering diare. Apa yang terjadi?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Chatbot: Berdasarkan gejalanya, kemungkinan ada masalah kesehatan. Saya sarankan segera periksakan ke dokter hewan. \n",
            "\n",
            "User: Tidak, hanya diare saja.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Chatbot: Berdasarkan gejalanya, kemungkinan ada masalah kesehatan. Saya sarankan segera periksakan ke dokter hewan. \n",
            "\n",
            "=== Test Model dengan Pertanyaan dari conv_045 ===\n",
            "User: Kucing saya sering mengeluarkan air mata dan matanya terlihat merah.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Chatbot: Berdasarkan gejalanya, kemungkinan ada masalah kesehatan. Saya sarankan segera periksakan ke dokter hewan. \n",
            "\n",
            "User: Ya, ada renovasi rumah dengan banyak debu.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Chatbot: Cobalah langkah penanganan awal seperti menjaga kebersihan, memberikan makanan ringan, dan konsultasikan ke dokter hewan jika berlanjut. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Pastikan file data sudah diupload, misalnya data2.json\n",
        "with open('data2.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "with open('stopword_list_tala.txt', 'r', encoding='utf-8') as f:\n",
        "    stop_words = f.read().splitlines()\n",
        "stop_words = set(w.strip().lower() for w in stop_words)\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = clean_text(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Kita akan membangun knowledge base berupa list dari (user_utterance_clean, bot_response)\n",
        "# Caranya: Untuk setiap conversation, kita iterate turns.\n",
        "# Setiap kali menemukan turn user, kita cek turn berikutnya apakah bot ada respons\n",
        "# Jika ya, simpan (user_utterance_clean, bot_utterance) ke knowledge base\n",
        "\n",
        "knowledge_base = []\n",
        "for conv in data:\n",
        "    turns = conv[\"turns\"]\n",
        "    for i in range(len(turns)-1):\n",
        "        if turns[i][\"speaker\"] == \"user\" and turns[i+1][\"speaker\"] == \"bot\":\n",
        "            user_utt = turns[i][\"utterance\"]\n",
        "            bot_utt = turns[i+1][\"utterance\"]\n",
        "            user_utt_clean = preprocess_text(user_utt)\n",
        "            knowledge_base.append((user_utt_clean, bot_utt))\n",
        "\n",
        "# Sekarang kita punya daftar pasangan (user_utterance_clean, bot_response)\n",
        "# Buat DataFrame untuk memudahkan\n",
        "df_kb = pd.DataFrame(knowledge_base, columns=[\"user_clean\",\"bot_response\"])\n",
        "\n",
        "# Vectorize user_utterance_clean untuk similarity\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df_kb[\"user_clean\"])\n",
        "\n",
        "def get_best_response(user_input):\n",
        "    # Preprocess query\n",
        "    user_query_clean = preprocess_text(user_input)\n",
        "    q_vec = vectorizer.transform([user_query_clean])\n",
        "    sims = cosine_similarity(q_vec, X)  # (1, n)\n",
        "    best_idx = sims[0].argmax()\n",
        "    best_score = sims[0][best_idx]\n",
        "    # Threshold opsional, misal jika similarity < 0.2 balas default\n",
        "    if best_score < 0.2:\n",
        "        return \"Maaf, saya belum memiliki informasi yang sesuai.\"\n",
        "    else:\n",
        "        return df_kb[\"bot_response\"].iloc[best_idx]\n",
        "\n",
        "# Contoh pengujian\n",
        "test_input = \"Kucing saya sering batuk dan hidungnya berair. Apa yang salah?\"\n",
        "response = get_best_response(test_input)\n",
        "print(\"User:\", test_input)\n",
        "print(\"Chatbot:\", response)\n",
        "\n",
        "# Anda juga dapat menguji dengan input lain yang mirip dengan dataset\n",
        "test_input2 = \"Anjing saya tidak mau makan dan dia mencret\"\n",
        "response2 = get_best_response(test_input2)\n",
        "print(\"User:\", test_input2)\n",
        "print(\"Chatbot:\", response2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHTFcW6oOS-f",
        "outputId": "1ff6fdef-79d3-4e67-dbbf-43168a42c70b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Kucing saya sering batuk dan hidungnya berair. Apa yang salah?\n",
            "Chatbot: Gejala ini dapat menunjukkan Infeksi Saluran Pernapasan Atas. Apakah kucing Anda sering terpapar udara dingin atau debu?\n",
            "User: Anjing saya tidak mau makan dan dia mencret\n",
            "Chatbot: Jika tetap tidak mau makan selama lebih dari 24 jam, segera bawa anjing Anda ke dokter hewan untuk pemeriksaan lebih lanjut.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Kita asumsikan fungsi get_best_response dan variabel pendukung sudah didefinisikan sebelumnya:\n",
        "# get_best_response(user_input) -> string\n",
        "\n",
        "# Jika Anda ingin memasukkan konteks multi-turn, misalnya menggabungkan dua turn terakhir:\n",
        "dialog_history = []\n",
        "MAX_HISTORY = 2  # banyaknya turn sebelumnya yang akan digabung\n",
        "\n",
        "def combined_context(new_input):\n",
        "    # Menggabungkan turn terakhir di dialog_history dengan current input\n",
        "    # untuk mempertahankan konteks multi-turn.\n",
        "    history_context = dialog_history[-MAX_HISTORY:] if len(dialog_history) > MAX_HISTORY else dialog_history\n",
        "    combined = \" \".join(history_context + [new_input])\n",
        "    return combined\n",
        "\n",
        "# Input widget\n",
        "input_box = widgets.Text(\n",
        "    placeholder='Ketik pertanyaan Anda di sini...',\n",
        "    description='User Input:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "send_button = widgets.Button(\n",
        "    description='Kirim',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_send_clicked(b):\n",
        "    user_input = input_box.value.strip()\n",
        "    if user_input:\n",
        "        dialog_history.append(user_input)\n",
        "        # Buat query dengan konteks multi-turn\n",
        "        query_with_context = combined_context(user_input)\n",
        "        response = get_best_response(query_with_context)\n",
        "        with output_area:\n",
        "            print(f\"User: {user_input}\")\n",
        "            print(f\"Chatbot: {response}\\n\")\n",
        "    input_box.value = \"\"  # kosongkan setelah kirim\n",
        "\n",
        "send_button.on_click(on_send_clicked)\n",
        "\n",
        "display(input_box, send_button, output_area)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655,
          "referenced_widgets": [
            "56ed564123124e01a265be2b4c8a42cc",
            "2afbf16c0b3f436c98532aed4edec9c5",
            "f09234e937ae49499349796086d786a2",
            "0cb8f5a5a8ca484c90cd58ab324b8b6e",
            "300297bf4a864ee985b7d953b62b7553",
            "e7e15f2b97db47e781a00e1ccae2095f",
            "0be1f579ee24469ab89c712855ceeba9",
            "68dee8ba5f3a449899c3ad1629e53a1a"
          ]
        },
        "id": "E8PLVn8lUuol",
        "outputId": "5f1ad406-693e-4482-83ee-d586b7ef2f84"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='User Input:', placeholder='Ketik pertanyaan Anda di sini...')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56ed564123124e01a265be2b4c8a42cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='Kirim', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cb8f5a5a8ca484c90cd58ab324b8b6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0be1f579ee24469ab89c712855ceeba9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hzc-7_DlVBqx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}